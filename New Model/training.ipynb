{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef73f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas numpy scikit-learn matplotlib joblib scipy\n",
      "Python: c:\\Users\\hamas\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n",
      "sklearn: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, importlib\n",
    "def pip_try(*pkgs):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
    "        print(\"✅\", \" \".join(pkgs))\n",
    "    except Exception as e:\n",
    "        print(\"⚠️  skip\", \" \".join(pkgs), \"->\", e)\n",
    "\n",
    "pip_try(\"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"joblib\", \"scipy\")\n",
    "import sklearn, numpy, pandas, scipy\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d25724a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import mode\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8025bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleFitLite:\n",
    "    def __init__(self, n_estimators=100, max_depth=3, min_samples_leaf=10,\n",
    "                 random_state=42, alpha=10.0):\n",
    "        self.rf = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        self.alpha = float(alpha)\n",
    "        self.lr = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"saga\",\n",
    "            C=1.0/max(self.alpha, 1e-8),\n",
    "            max_iter=1000,\n",
    "            tol=1e-3,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        self.classes_ = None\n",
    "\n",
    "    def _rules_matrix(self, X):\n",
    "        mats = []\n",
    "        for est in self.rf.estimators_:\n",
    "            M = est.decision_path(X)\n",
    "            if M.shape[1] > 1:\n",
    "                M = M[:, 1:]\n",
    "            mats.append(M)\n",
    "        if len(mats) == 1:\n",
    "            return mats[0].tocsr()\n",
    "        return sp.hstack(mats, format=\"csr\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        self.rf.fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        R = self._rules_matrix(X)\n",
    "        self.lr.fit(R, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X)\n",
    "        R = self._rules_matrix(X)\n",
    "        return self.lr.predict_proba(R)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        idx = probs.argmax(axis=1)\n",
    "        return np.array([self.lr.classes_[i] for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ac1dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "Shape: (6854, 28)\n",
      "Target: Role\n",
      "\n",
      "Class distribution:\n",
      "Role\n",
      "AI ML Specialist                   884\n",
      "Software Developer                 516\n",
      "Application Support Engineer       472\n",
      "Networking Engineer                458\n",
      "Project Manager                    458\n",
      "Business Analyst                   442\n",
      "Cyber Security Specialist          434\n",
      "Graphics Designer                  415\n",
      "Helpdesk Engineer                  411\n",
      "Software tester                    388\n",
      "Database Administrator             388\n",
      "Hardware Engineer                  380\n",
      "Technical Writer                   379\n",
      "Customer Service Executive         277\n",
      "API Specialist                     276\n",
      "Information Security Specialist    276\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric features: 27\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./dataset_normalized_clean.csv\"\n",
    "TARGET_COL = \"Role\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"\\nClass distribution:\\n{df[TARGET_COL].value_counts()}\")\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "print(f\"\\nNumeric features: {len(num_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce12d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SKILL CATEGORIZATION\n",
      "============================================================\n",
      "Hard Skills (15): ['Database Fundamentals', 'Computer Architecture', 'Distributed Computing Systems']...\n",
      "Soft Skills (12): ['Technical Communication', 'Communication skills', 'Openness']...\n"
     ]
    }
   ],
   "source": [
    "def categorize_skills(columns):\n",
    "    soft_skill_keywords = [\n",
    "        'openness', 'conscientousness', 'extraversion', 'agreeableness', \n",
    "        'neuroticism', 'emotional', 'communication', 'leadership', \n",
    "        'teamwork', 'creativity', 'critical', 'problem', 'conversation',\n",
    "        'hedonism', 'enhancement', 'transcendence', 'change'\n",
    "    ]\n",
    "    \n",
    "    hard_skills = []\n",
    "    soft_skills = []\n",
    "    \n",
    "    for col in columns:\n",
    "        col_lower = col.lower()\n",
    "        is_soft = any(keyword in col_lower for keyword in soft_skill_keywords)\n",
    "        \n",
    "        if is_soft:\n",
    "            soft_skills.append(col)\n",
    "        else:\n",
    "            hard_skills.append(col)\n",
    "    \n",
    "    return hard_skills, soft_skills\n",
    "\n",
    "hard_skill_cols, soft_skill_cols = categorize_skills(num_cols)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL CATEGORIZATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Hard Skills ({len(hard_skill_cols)}): {hard_skill_cols[:3]}...\")\n",
    "print(f\"Soft Skills ({len(soft_skill_cols)}): {soft_skill_cols[:3]}...\")\n",
    "\n",
    "X_hard = X[hard_skill_cols].copy()\n",
    "X_soft = X[soft_skill_cols].copy()\n",
    "feature_columns = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5878e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IMPROVED TRAIN/VAL/TEST SPLIT (60/20/20)\n",
      "============================================================\n",
      "Train: 4112 (60.0%)\n",
      "Val:   1371 (20.0%)\n",
      "Test:  1371 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVED TRAIN/VAL/TEST SPLIT (60/20/20)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 * 0.8 = 0.2\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "X_train_hard, X_val_hard, X_test_hard = X_train[hard_skill_cols], X_val[hard_skill_cols], X_test[hard_skill_cols]\n",
    "X_train_soft, X_val_soft, X_test_soft = X_train[soft_skill_cols], X_val[soft_skill_cols], X_test[soft_skill_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee490fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing pipelines created\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer_hard = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "preprocess_hard = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer_hard, hard_skill_cols)\n",
    "])\n",
    "\n",
    "numeric_transformer_soft = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "preprocess_soft = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer_soft, soft_skill_cols)\n",
    "])\n",
    "\n",
    "print(\"✅ Preprocessing pipelines created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a5ef1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING WITH IMPROVED HYPERPARAMETERS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING WITH IMPROVED HYPERPARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Preprocess\n",
    "pre_X_train_hard = preprocess_hard.fit_transform(X_train_hard)\n",
    "pre_X_val_hard = preprocess_hard.transform(X_val_hard)\n",
    "pre_X_test_hard = preprocess_hard.transform(X_test_hard)\n",
    "\n",
    "pre_X_train_soft = preprocess_soft.fit_transform(X_train_soft)\n",
    "pre_X_val_soft = preprocess_soft.transform(X_val_soft)\n",
    "pre_X_test_soft = preprocess_soft.transform(X_test_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e576aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Hard Skills Model...\n",
      "  Val  - Acc: 0.9198, F1: 0.8488\n",
      "  Test - Acc: 0.9198, F1: 0.8488\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Hard Skills Model...\")\n",
    "rf_lite_hard = RuleFitLite(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    alpha=10.0\n",
    ")\n",
    "rf_lite_hard.fit(pre_X_train_hard, y_train)\n",
    "\n",
    "y_pred_rf_hard_val = rf_lite_hard.predict(pre_X_val_hard)\n",
    "y_pred_rf_hard_test = rf_lite_hard.predict(pre_X_test_hard)\n",
    "\n",
    "acc_rf_hard_val = accuracy_score(y_val, y_pred_rf_hard_val)\n",
    "f1_rf_hard_val = f1_score(y_val, y_pred_rf_hard_val, average=\"macro\")\n",
    "\n",
    "acc_rf_hard_test = accuracy_score(y_test, y_pred_rf_hard_test)\n",
    "f1_rf_hard_test = f1_score(y_test, y_pred_rf_hard_test, average=\"macro\")\n",
    "\n",
    "print(f\"  Val  - Acc: {acc_rf_hard_val:.4f}, F1: {f1_rf_hard_val:.4f}\")\n",
    "print(f\"  Test - Acc: {acc_rf_hard_test:.4f}, F1: {f1_rf_hard_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b8cd86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Soft Skills Model...\n",
      "  Val  - Acc: 0.8913, F1: 0.9011\n",
      "  Test - Acc: 0.8899, F1: 0.8977\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Soft Skills Model...\")\n",
    "rf_lite_soft = RuleFitLite(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    alpha=10.0\n",
    ")\n",
    "rf_lite_soft.fit(pre_X_train_soft, y_train)\n",
    "\n",
    "y_pred_rf_soft_val = rf_lite_soft.predict(pre_X_val_soft)\n",
    "y_pred_rf_soft_test = rf_lite_soft.predict(pre_X_test_soft)\n",
    "\n",
    "acc_rf_soft_val = accuracy_score(y_val, y_pred_rf_soft_val)\n",
    "f1_rf_soft_val = f1_score(y_val, y_pred_rf_soft_val, average=\"macro\")\n",
    "\n",
    "acc_rf_soft_test = accuracy_score(y_test, y_pred_rf_soft_test)\n",
    "f1_rf_soft_test = f1_score(y_test, y_pred_rf_soft_test, average=\"macro\")\n",
    "\n",
    "print(f\"  Val  - Acc: {acc_rf_soft_val:.4f}, F1: {f1_rf_soft_val:.4f}\")\n",
    "print(f\"  Test - Acc: {acc_rf_soft_test:.4f}, F1: {f1_rf_soft_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9e291a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Predictions...\n",
      "  Val  - Acc: 1.0000, F1: 1.0000\n",
      "  Test - Acc: 1.0000, F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEnsemble Predictions...\")\n",
    "\n",
    "proba_hard_val = rf_lite_hard.predict_proba(pre_X_val_hard)\n",
    "proba_soft_val = rf_lite_soft.predict_proba(pre_X_val_soft)\n",
    "proba_ensemble_val = 0.6 * proba_hard_val + 0.4 * proba_soft_val\n",
    "y_pred_ensemble_val = rf_lite_hard.lr.classes_[proba_ensemble_val.argmax(axis=1)]\n",
    "\n",
    "acc_ensemble_val = accuracy_score(y_val, y_pred_ensemble_val)\n",
    "f1_ensemble_val = f1_score(y_val, y_pred_ensemble_val, average=\"macro\")\n",
    "\n",
    "proba_hard_test = rf_lite_hard.predict_proba(pre_X_test_hard)\n",
    "proba_soft_test = rf_lite_soft.predict_proba(pre_X_test_soft)\n",
    "proba_ensemble_test = 0.6 * proba_hard_test + 0.4 * proba_soft_test\n",
    "y_pred_ensemble_test = rf_lite_hard.lr.classes_[proba_ensemble_test.argmax(axis=1)]\n",
    "\n",
    "acc_ensemble_test = accuracy_score(y_test, y_pred_ensemble_test)\n",
    "f1_ensemble_test = f1_score(y_test, y_pred_ensemble_test, average=\"macro\")\n",
    "\n",
    "print(f\"  Val  - Acc: {acc_ensemble_val:.4f}, F1: {f1_ensemble_val:.4f}\")\n",
    "print(f\"  Test - Acc: {acc_ensemble_test:.4f}, F1: {f1_ensemble_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "026d6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OVERFITTING CHECK\n",
      "============================================================\n",
      "Hard Skills - Train: 0.9190, Val: 0.9198, Test: 0.9198\n",
      "Soft Skills - Train: 0.9039, Val: 0.8913, Test: 0.8899\n",
      "\n",
      "Generalization Gap:\n",
      "  Hard: -0.0007 ✅ OK\n",
      "  Soft: 0.0141 ✅ OK\n",
      "\n",
      "✅ Training accuracy looks reasonable\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERFITTING CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_train_hard = rf_lite_hard.predict(pre_X_train_hard)\n",
    "acc_train_hard = accuracy_score(y_train, y_pred_train_hard)\n",
    "\n",
    "y_pred_train_soft = rf_lite_soft.predict(pre_X_train_soft)\n",
    "acc_train_soft = accuracy_score(y_train, y_pred_train_soft)\n",
    "\n",
    "print(f\"Hard Skills - Train: {acc_train_hard:.4f}, Val: {acc_rf_hard_val:.4f}, Test: {acc_rf_hard_test:.4f}\")\n",
    "print(f\"Soft Skills - Train: {acc_train_soft:.4f}, Val: {acc_rf_soft_val:.4f}, Test: {acc_rf_soft_test:.4f}\")\n",
    "\n",
    "gap_hard = acc_train_hard - acc_rf_hard_test\n",
    "gap_soft = acc_train_soft - acc_rf_soft_test\n",
    "\n",
    "print(f\"\\nGeneralization Gap:\")\n",
    "print(f\"  Hard: {gap_hard:.4f} {'⚠️ HIGH' if gap_hard > 0.15 else '✅ OK'}\")\n",
    "print(f\"  Soft: {gap_soft:.4f} {'⚠️ HIGH' if gap_soft > 0.15 else '✅ OK'}\")\n",
    "\n",
    "if acc_train_hard > 0.95 or acc_train_soft > 0.95:\n",
    "    print(\"\\n⚠️  WARNING: Training accuracy > 0.95 - possible overfitting!\")\n",
    "    print(\"   Consider: further reduce max_depth, increase min_samples_leaf\")\n",
    "else:\n",
    "    print(\"\\n✅ Training accuracy looks reasonable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "886e7b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SANITY TESTS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SANITY TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def predict_jobs_helper(user_data):\n",
    "    user_data_hard = {k: user_data.get(k, np.nan) for k in hard_skill_cols}\n",
    "    user_data_soft = {k: user_data.get(k, np.nan) for k in soft_skill_cols}\n",
    "    \n",
    "    user_df_hard = pd.DataFrame([user_data_hard])\n",
    "    user_df_soft = pd.DataFrame([user_data_soft])\n",
    "    \n",
    "    user_pre_hard = preprocess_hard.transform(user_df_hard)\n",
    "    user_pre_soft = preprocess_soft.transform(user_df_soft)\n",
    "    \n",
    "    proba_hard = rf_lite_hard.predict_proba(user_pre_hard)[0]\n",
    "    proba_soft = rf_lite_soft.predict_proba(user_pre_soft)[0]\n",
    "    proba = 0.6 * proba_hard + 0.4 * proba_soft\n",
    "    \n",
    "    top_idx = proba.argmax()\n",
    "    top_job = rf_lite_hard.lr.classes_[top_idx]\n",
    "    top_prob = proba[top_idx]\n",
    "    \n",
    "    return top_job, top_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3a0f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. All skills = 5 (expect: technical/data role)\n",
      "   Result: AI ML Specialist (prob: 0.285)\n",
      "   ✅ PASS - Got technical role\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. All skills = 5 (expect: technical/data role)\")\n",
    "all_max = {skill: 5 for skill in feature_columns}\n",
    "job, prob = predict_jobs_helper(all_max)\n",
    "print(f\"   Result: {job} (prob: {prob:.3f})\")\n",
    "expected_tech = ['Data Scientist', 'AI ML Specialist', 'Software Engineer', \n",
    "                 'Software Developer', 'Application Support Engineer']\n",
    "if any(exp in job for exp in expected_tech):\n",
    "    print(\"   ✅ PASS - Got technical role\")\n",
    "else:\n",
    "    print(f\"   ⚠️  UNEXPECTED - Expected technical role, got {job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff16e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. All skills = 1 (expect: entry-level role)\n",
      "   Result: Software Developer (prob: 0.318)\n",
      "   ℹ️  No strict expectation for all-low scores\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. All skills = 1 (expect: entry-level role)\")\n",
    "all_min = {skill: 1 for skill in feature_columns}\n",
    "job, prob = predict_jobs_helper(all_min)\n",
    "print(f\"   Result: {job} (prob: {prob:.3f})\")\n",
    "print(\"   ℹ️  No strict expectation for all-low scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51e3bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Only hard skills = 5, soft skills = 1\n",
      "   Result: Software Developer (prob: 0.347)\n",
      "   ℹ️  Should prefer tech-heavy roles\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Only hard skills = 5, soft skills = 1\")\n",
    "only_hard = {**{h: 5 for h in hard_skill_cols}, \n",
    "             **{s: 1 for s in soft_skill_cols}}\n",
    "job, prob = predict_jobs_helper(only_hard)\n",
    "print(f\"   Result: {job} (prob: {prob:.3f})\")\n",
    "print(\"   ℹ️  Should prefer tech-heavy roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a165a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Only soft skills = 5, hard skills = 1\n",
      "   Result: Technical Writer (prob: 0.452)\n",
      "   ✅ PASS - Got soft-skill role\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Only soft skills = 5, hard skills = 1\")\n",
    "only_soft = {**{h: 1 for h in hard_skill_cols}, \n",
    "             **{s: 5 for s in soft_skill_cols}}\n",
    "job, prob = predict_jobs_helper(only_soft)\n",
    "print(f\"   Result: {job} (prob: {prob:.3f})\")\n",
    "expected_soft = ['Business Analyst', 'Project Manager', 'Technical Writer', \n",
    "                 'Customer Service Executive']\n",
    "if any(exp in job for exp in expected_soft):\n",
    "    print(\"   ✅ PASS - Got soft-skill role\")\n",
    "else:\n",
    "    print(f\"   ℹ️  Got {job} - may or may not be expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e72e3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING IMPROVED MODEL ARTIFACTS\n",
      "============================================================\n",
      "✅ Saved model files\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING IMPROVED MODEL ARTIFACTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "artifacts_dir = \"artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(rf_lite_hard, os.path.join(artifacts_dir, \"rf_hard_normalized.pth\"))\n",
    "joblib.dump(rf_lite_soft, os.path.join(artifacts_dir, \"rf_soft_normalized.pth\"))\n",
    "joblib.dump(preprocess_hard, os.path.join(artifacts_dir, \"preprocess_hard_normalized.pth\"))\n",
    "joblib.dump(preprocess_soft, os.path.join(artifacts_dir, \"preprocess_soft_normalized.pth\"))\n",
    "\n",
    "print(\"✅ Saved model files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaf21336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved metadata files\n",
      "\n",
      "============================================================\n",
      "✅ TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Final Test Results:\n",
      "  Ensemble Accuracy: 1.0000\n",
      "  Ensemble F1 Macro: 1.0000\n",
      "\n",
      "Artifacts saved to: artifacts/\n"
     ]
    }
   ],
   "source": [
    "metadata = {\n",
    "    \"hard_skills\": hard_skill_cols,\n",
    "    \"soft_skills\": soft_skill_cols,\n",
    "    \"ensemble_weights\": {\n",
    "        \"hard\": 0.6,\n",
    "        \"soft\": 0.4\n",
    "    },\n",
    "    \"hyperparameters\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 3,\n",
    "        \"min_samples_leaf\": 10,\n",
    "        \"alpha\": 10.0\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"hard_skills\": {\n",
    "            \"train_acc\": float(acc_train_hard),\n",
    "            \"val_acc\": float(acc_rf_hard_val),\n",
    "            \"test_acc\": float(acc_rf_hard_test),\n",
    "            \"val_f1\": float(f1_rf_hard_val),\n",
    "            \"test_f1\": float(f1_rf_hard_test)\n",
    "        },\n",
    "        \"soft_skills\": {\n",
    "            \"train_acc\": float(acc_train_soft),\n",
    "            \"val_acc\": float(acc_rf_soft_val),\n",
    "            \"test_acc\": float(acc_rf_soft_test),\n",
    "            \"val_f1\": float(f1_rf_soft_val),\n",
    "            \"test_f1\": float(f1_rf_soft_test)\n",
    "        },\n",
    "        \"ensemble\": {\n",
    "            \"val_acc\": float(acc_ensemble_val),\n",
    "            \"test_acc\": float(acc_ensemble_test),\n",
    "            \"val_f1\": float(f1_ensemble_val),\n",
    "            \"test_f1\": float(f1_ensemble_test)\n",
    "        }\n",
    "    },\n",
    "    \"dataset_shape\": df.shape,\n",
    "    \"num_classes\": len(y.unique()),\n",
    "    \"train_val_test_split\": {\n",
    "        \"train_size\": len(X_train),\n",
    "        \"val_size\": len(X_val),\n",
    "        \"test_size\": len(X_test),\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(artifacts_dir, \"model_metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(os.path.join(artifacts_dir, \"feature_columns.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(feature_columns, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved metadata files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"  Ensemble Accuracy: {acc_ensemble_test:.4f}\")\n",
    "print(f\"  Ensemble F1 Macro: {f1_ensemble_test:.4f}\")\n",
    "print(f\"\\nArtifacts saved to: {artifacts_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
